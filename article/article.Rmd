---
title:  |
        | The Effect of Legislature Size on Public Spending:
        | A Meta-Analysis
author: 
  - Huzeyfe Alptekin[^huzeyfe]
  - Danilo Freire[^danilo]
  - Umberto Mignozzetti[^umberto]
  - Catarina Roman[^catarina]
date: \today
thanks: "The authors thank Guilherme Duarte, Robert Myles McDonnell, and David Skarbek for their constructive feedback. We also thank Cedric Antunes, Luis Castro, Giovanna França, Julia Oriente, and Lucas Mingardi for their excellent research assistance. Replication materials are available at <https://github.com/danilofreire/legislature-size-meta-analysis>. We kindly acknowledge funding from the São Paulo State Science Foundation (FAPESP grant number 2018/00646-1)."
abstract: "In a seminal article, @weingast1981political argue that there is a positive relationship between legislature size and inefficiency in public expenditures. Their proposition is currently known as the \"law of $1/n$\" and has been widely debated in political science and public administration. However, recent studies have questioned the validity of the theory. In this letter, we estimate the first meta-analysis of the relationship between the number of legislators and public spending. Based on a sample of 29 articles, we find no robust evidence for the effect of legislature size on government budgets. Yet the aggregate results show significant heterogeneity. While earlier studies provide moderate support for the \"law of $1/n$\", papers using causal inference methods consistently find a negative relationship between seats and spending. The available evidence also indicates that proportional representation and mixed voting systems are no more likely to overspend than majoritarian ones."
abstractspacing: double
keywords: distributive politics; law of $1/n$; legislature size; meta-analysis; public spending
jelcodes: H21; H23; H50; H61
fontsize: 11pt
margin: 2cm
urlcolor: darkblue
linkcolor: Mahogany
citecolor: Mahogany
spacing: double
papersize: a4paper
bibliography: references.bib
biblio-style: apalike
output:
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    number_sections: yes
    keep_tex: no
    toc: no
    toc_depth: 3
    template: article-template.latex
    md_extensions: +raw_attribute
---

```{r, message=FALSE, warning=FALSE, echo=FALSE, results='hide'}
# Knitr options
knitr::opts_chunk$set(fig.pos = "H") # holds figure position
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning=FALSE, echo=FALSE, results='hide'}
# Clean up
rm(list = ls())

## Starting
set.seed(732578) # From random.org

# Needed packages
pkgs <- c("tidyverse", "meta", "metafor",
          "readxl", "data.table",
          "knitr", "gridGraphics", "gridExtra",
          "ggpubr", "kableExtra", "magick")

# Install if not already installed
installIfNot <- function(x) {
  if (x %in% rownames(installed.packages()) == FALSE)
    install.packages(x, dependencies = T,
					 repos = "http://cran.us.r-project.org")
}
lapply(pkgs, installIfNot)

# Load packages
lapply(pkgs, require, character.only = T)
devtools::install_github("isubirana/compareGroups")
library("compareGroups")

# Load datasets
load("../dataset/dataCoefs.RData")

# Build plot function for forest plots
build_forest <- function(mod, capt, lsize = 22, ttl = NULL) {
  # Build dataset for plot
  mod2 <- tibble(
    TE = mod$TE,
    seTE = mod$seTE,
    studlab = mod$studlab,
    lower = mod$lower,
    upper = mod$upper,
    group = "A") %>%
    bind_rows(.,
              aux = tibble(
                TE = c(mod$TE.random, NA),
                seTE = c(mod$seTE.random, NA),
                studlab = c("Overall Effect",
                            "Prediction Interval"),
                lower = c(mod$lower.random,
                          mod$lower.predict),
                upper = c(mod$upper.random,
                          mod$upper.predict),
                group = "B")) %>%
    group_by(studlab) %>%
    mutate(studlab2 = paste0(studlab, "_", 1:n())) %>%
    ungroup()

  # Graph limits
  limg <- max(abs(c(mod2$lower, mod2$upper)))

  # Build plot
  p <- mod2 %>%
    ggplot(aes(y = reorder(studlab2, TE),
               x = TE, xmin = lower, xmax = upper)) +
    geom_point(aes(color = group)) +
    geom_errorbarh(aes(color = group),
                   height = 0.1) +
    scale_color_manual(values = c("#000000", "#8b0000")) +
    scale_x_continuous(limits = c(-1.1 * limg, 1.1 * limg)) +
    scale_y_discrete(
      labels = function(x)
        str_replace(x, "_[0-9]*$", "")) +
    geom_vline(xintercept = 0,
               color = "#000000", linetype = "dashed") +
    labs(x = "",
         y = "") +
    facet_grid(group~., scales = "free", space = "free") +
    labs(caption = capt,
         title = ttl) +
    theme_minimal() %+replace%
    theme(strip.text.y = element_blank(),
          legend.position = "none",
          axis.text.y = element_text(size = .8 * lsize,
                                     hjust = 1),
          axis.text.x = element_text(size = .6 * lsize,
                                     hjust = 1.1),
          plot.caption = element_text(size = lsize),
          plot.title.position = "plot",
          plot.title = element_text(hjust = 0.5,
                                    face = "bold",
                                    margin = margin(0, 0, 10, 0)),
          panel.grid.major = element_blank())
  return(p)
}

# Build forest plot for heterogeneous analysis
# Build plot function for forest plots
build_forest_het <- function(mod, capt, lsize = 22, ttl = NULL, hetvar = NULL) {
  mod <- update(mod, byvar = hetvar, print.byvar = F)
  
  # Build dataset for plot
  mod2 <- tibble(
    byvar = mod$byvar,
    TE = mod$TE,
    seTE = mod$seTE,
    studlab = mod$studlab,
    lower = mod$lower,
    upper = mod$upper,
    group = "A") %>%
    arrange(byvar)
  auxmod <- tibble()
  for (i in rev(mod$bylevs)){
    auxmod <- rbind(auxmod, tibble(byvar = i,
                    TE = NA,
                    seTE = NA,
                    studlab = toupper(i),
                    lower = NA,
                    upper = NA,
                    group = "B"))
    auxmod <- rbind(auxmod, 
                    filter(mod2, byvar==i) %>% 
                      arrange(desc(TE)))
    auxmod <- rbind(auxmod, tibble(
      byvar = i,
      TE = mod$TE.random.w[which(mod$bylevs==i)],
      seTE = mod$seTE.random.w[which(mod$bylevs==i)],
      studlab = 'Subgroup Effect',
      lower = mod$lower.random.w[which(mod$bylevs==i)],
      upper = mod$upper.random.w[which(mod$bylevs==i)],
      group = "B"))
  }
  auxmod <- rbind(auxmod, tibble(
    byvar = NA,
    TE = c(mod$TE.random, NA),
    seTE = c(mod$seTE.random, NA),
    studlab = c("Overall Effect", "Prediction Interval"),
    lower = c(mod$lower.random, mod$lower.predict),
    upper = c(mod$upper.random, mod$upper.predict),
    group = "B"))
  mod2 <- data.frame(auxmod)
  mod2$byvar <- toupper(mod2$byvar)
  TEaux <- mod2$TE
  TEaux[mod2$studlab== 'Subgroup Effect'] = TEaux[mod2$studlab== 'Subgroup Effect'] - 100
  
  # Graph limits
  limg <- max(abs(c(mod2$lower, mod2$upper)))
  
  # Build plot
  p <- mod2 %>%
    ggplot(aes(y = reorder(studlab, TEaux),
               x = TE, xmin = lower, xmax = upper)) +
    geom_point(aes(color = group)) +
    geom_errorbarh(aes(color = group),
                   height = 0.1) +
    scale_color_manual(values = c("#000000", "#8b0000")) +
    scale_x_continuous(limits = c(-1.1 * limg, 1.1 * limg)) +
    scale_y_discrete(
      labels = function(x)
        str_replace(x, "_[0-9]*$", "")) +
    geom_vline(xintercept = 0,
               color = "#000000", linetype = "dashed") +
    labs(x = "",
         y = "") +
    facet_grid(byvar~., scales = "free", space = "free") +
    labs(caption = capt,
         title = ttl) +
    theme_minimal() %+replace%
    theme(strip.text.y = element_blank(),
          legend.position = "none",
          axis.text.y = element_text(size = .8 * lsize,
                                     hjust = 1),
          axis.text.x = element_text(size = .6 * lsize,
                                     hjust = 1.1),
          plot.caption = element_text(size = lsize),
          plot.title.position = "plot",
          plot.title = element_text(hjust = 0.5,
                                    face = "bold",
                                    margin = margin(0, 0, 10, 0)),
          panel.grid.major = element_blank())
  return(p)
}
```

[^huzeyfe]: Research Associate, Contemporary Brazilian History Research and Documentation Center, School of Social Sciences, Fundação Getulio Vargas, <huzeyfealptekin@gmail.com>.

[^danilo]: Senior Lecturer, School of Social and Political Sciences, University of Lincoln, <danilofreire@gmail.com>, <https://danilofreire.github.io>. 

[^umberto]: Visiting Assistant Professor, Quantitative Theory and Methods Department, Emory University, <umberto.mignozzetti@emory.edu>, <http://umbertomig.com>. Corresponding author.

[^catarina]: PhD Student, Department of Political Science, University of California San Diego, <catarinamroman@gmail.com>, <http://catarinaroman.github.io>.

\newpage

# Introduction
\label{sec:intro}

Over the past decades, a large literature has examined the relationship between
legislature size and public expenditure. @weingast1981political provided the
general framework to analyse distributive politics. The authors argue that the
larger the number of legislative districts ($n$), the smaller the share of tax
burden each one will bear ($1/n$), thus legislators have an incentive to
overspend in their districts and transfer the costs to the entire polity. Early
studies that empirically tested the "law of $1/n$", as the theory is currently
known, indeed found a positive correlation between the number of legislature
seats and different measures of government spending, although these first
results were mainly based on US state legislatures and the effect was often
limited to one house [e.g., @baqir2002districting; @gilligan1995deviations;
@gilligan2001fiscal]. 

Later research, however, has questioned the validity of the "law of $1/n$".
@primo2008distributive affirm that, due to spatial spillovers, a collection of
small districts can supply public goods more efficiently than the central
government. The authors conclude that a "reverse law of $1/n$" may hold,
wherein a higher number of legislators in small constituencies decrease the
overall public spending. Similarly, @primo2006stop and @chen2007law find that
lower and upper chambers may have mixed effects on government spending, while
@petterssonlidbom2012size argues that the impact of larger chamber sizes is
negative when using data from Finland and Sweden.

Since many empirical tests of the "law of $1/n$" have produced conflicting
results, scholars have expanded this research agenda and closely investigated
how institutional factors condition the original formulation of the theory. For
instance, authors such as @crowley2019law and @pecorino2018supermajority
accurately point out that collective action problems have been overlooked in
the literature, and recent findings indicate that bicameralism
[@maldonado2013legislatures], intergovernmental competition
[@crowley2015local], redistricting [@lee2018court], and party ideology
[@bjedov2014impact] strongly influence the relationship between seats and
spending. Moreover, the literature has increasingly applied causal inference
designs to estimate the effect of the "law of $1/n$", and in contrast to
previous studies using panel data, regression discontinuity designs generally
indicate that more legislators decrease public expenditures
[@debenedetto2018effect; @hohmann2017effect; @lewis2019legislature]. In this
respect, scholars have long been aware of the theoretical and empirical
limitations of the "law of $1/n$", and the proliferation of new studies reflect
a conscious attempt to assess the robustness of the theory [@crowley2019law].

In this letter, we conduct the first meta-analysis that tests the generality of
the "law of $1/n$". We select `r length(unique(dat$id))` articles that
use quantitative methods to evaluate the impact of legislature size over
government spending across several dimensions. Our study sample mirrors the
diversity of the literature. Out of the `r dim(dat)[1]` coefficients
included in our main analysis, `r as.numeric(round(prop.table(table(dat$scoefnd))*100, 1)[which(names(prop.table(table(dat$scoefnd)))=='Positive Significant')])`\% of
them are positive and statistically significant, `r as.numeric(round(prop.table(table(dat$scoefnd))*100, 1)[which(names(prop.table(table(dat$scoefnd)))=='Positive Insignificant')])`\%
are positive and statistically insignificant, `r as.numeric(round(prop.table(table(dat$scoefnd))*100, 1)[which(names(prop.table(table(dat$scoefnd)))=='Negative Insignificant')])`\%
are negative and statistically insignificant, and `r as.numeric(round(prop.table(table(dat$scoefnd))*100, 1)[which(names(prop.table(table(dat$scoefnd)))=='Negative Significant')])`\% are
negative and statistically significant. Given the volume and the disparity of
the studies, we employ meta-analysis to summarise the results. Meta-analysis
provides a rigorous approach to combine heterogeneous outcomes into a single
estimation, and it allows scholars to gain valuable insights from the
aggregated data [@cooper2019handbook; @hedges1985statistical]. Meta-analysis
can also identify potential sources of study variability, enabling researchers
to assess threats to external validity and direct future efforts into more
promising areas of academic inquiry [@doucouliagos2008democracy]. Research
synthesis methods have been successfully applied in medicine and psychology
since the 1970s [@glass2015meta], and our work contributes to the burgeoning
literature that uses meta-analytic methods to understand challenging questions
in political science [@costa2017responsive; @doucouliagos2008democracy;
@green2013field; @lau2007effects; @schwarz2020supporting].

We run binomial tests and meta-regressions to further evaluate the relationship
between legislature size and government expenditures. We use binomial tests
to assess whether the proportions of positive and negative coefficients in our
sample are statistically different from each other. In the meta-regressions, we
measure the effect of five moderators that capture different sources of
heterogeneity in the literature. As our sample includes both published and
unpublished articles, we also construct a series of funnel plots to test for
publication bias in existing research on the "law of $1/n$"
[@easterbrook1991publication; @gerber2001testing].

Aggregate results indicate that legislature size has no significant impact on
public spending. All of our main meta-analysis estimates show that the overall
effect is not statistically different from zero, thus confirming the
conflicting findings reported by the literature. However, when we look only at
articles that employ regression discontinuity designs, we see that all three
papers included in our sample suggest that a higher number of legislators leads
to lower public spending [@debenedetto2018effect; @hohmann2017effect;
@lewis2019legislature]. In this regard, it is possible that methodological
choices partially explain the divergent results observed in the literature, as
studies that use causal inference methods consistently point to the same
direction. One limitation of this finding is that these studies only test the
impact of lower house size on the natural logarithm of expenditure per capita,
thus it remains unclear whether the results hold with other variables.

The meta-regressions provide additional evidence that our study sample is
highly heterogeneous and that effect sizes differ substantially according to
study specifications. When using our extended sample of `r dim(fulldat)[1]`
coefficients, we find that unicameralism is associated with higher public
spending, as predicted by the "law of $1/n$". Since most unicameral
legislatures are located in local governments (municipalities or districts),
this result supports the theory strictly in its first formulation. Moreover,
our meta-regressions indicate that larger upper chambers spend more in terms of
per capita expenditure than lower chambers, a result that also appears in the
binomial tests. Non-majoritarian voting systems decrease government spending as
a percentage of GDP, but they do not have a relevant impact on the other
measures of public expenditure, following the idea that the $1/n$ effect grows
weaker as the empirical cases distance from the original definition of the law.
Finally, meta-regression results confirm that regression discontinuity models
reduce public spending estimates.

In summary, our results are in line with previous findings that lend partial
support to the law of $1/n$ [@chen2007law; @crowley2015local; @primo2006stop].
An assessment of the effects of collective action costs in these analyses is
crucial to determine the full mechanism operating behind these results.
Overall, our analysis does not provide robust support for the theory as
originally conceived. 

# Data and Methods

We compiled our study sample in three search rounds. In the first round, we
gathered data from three large academic databases (Scopus, Microsoft Academic,
and Google Scholar) and looked for studies that were published in English and
cited \citet{weingast1981political}, as it is the foundational work in the
literature on the "law of $1/n$". To ensure that our sample was comparable, we
only selected papers that used quantitative methods to analyse
data\footnote{Since meta-analysis requires a single estimate per observation,
we excluded articles that use interaction terms or quadratic specifications of
our selected variables. Please refer to Section C in the Supplementary Material
for a detailed description of the selection procedure. We also included two
PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses)
flow diagrammes \citep{liberati2009prisma} showing the number of resulting
papers after each review step.}. After this stage, we identified six
measurements that the literature often employs to quantify government
expenditure and legislature size. For government expenditure, our study sample
uses (i) public expenditure as a share of GDP; (ii) public expenditure per
capita; and (iii) the natural logarithm of public expenditure per capita as its
main variables of interest. In regards to legislature size, the variables are
(i) lower chamber size; (ii) natural logarithm of lower chamber size; and (iii)
upper house size\footnote{There are a few important nuances concerning coding
of these variables. Unicameralism, for example, is captured both by lower
chamber size ($n = 7$) and by log lower chamber size ($n = 5$). Since much of
the literature estimates how institutional designs affect this relationship,
ours and many other articles use both lower and upper chamber sizes as main
explanatory variables. We did not find any article that used the natural
logarithm of upper chamber size in their models.}. 

In the second round, we did not require articles to cite @weingast1981political
and used a keyword-based query on Google Scholar to broaden the scope of the
first search. The search string contained terms strongly associated with the
literature on the "law of $1/n$" and was as follows: `("upper chamber size" OR
"lower chamber size" OR "council size" OR "parliament size" OR "legislature
size" OR "number of legislators" OR "legislative size") AND ("spending" OR
"expenditure" OR "government size")`. We again restricted the search to
articles written in English which employed quantitative methods. This search
added two new results to our sample [@coate2011government;
@debenedetto2018effect], but neither of them included variables beyond the six
measures we had previously identified. In the third search round, we looked
into the personal webpages of every author whom we had already included in our
sample. The purpose of this manual search was to assess whether there was any
working paper or unpublished manuscript that we had missed in the two former
queries. All papers we found in the last search had already been included in
our sample. Combined, the three searches produced a dataset of 
`r length(unique(dat$id))` studies as of the 10\textsuperscript{th} of March 2021.
Table \ref{tab:papers} contains the full list of articles we analyse in this
paper.

\footnotesize
\begin{longtable}{>{\raggedright\arraybackslash}p{3.9cm}>{\centering\arraybackslash}p{1.5cm}>{\centering\arraybackslash}p{2cm}>{\centering\arraybackslash}p{2.3cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{2cm}>{\centering\arraybackslash}p{1.1cm}}
\caption{Papers included in the meta-analysis, ordered by year of appearance}\\
\toprule
\raggedright Author(s) & \centering Journal & \centering Country & \centering Dependent Variable & \centering Method & \centering Institutional Design & \centering Electoral System
\tabularnewline
\midrule
\endhead
```{r papers, echo = FALSE, results = 'asis', cache = T}
build_nams <- function(x) {
  x_ <- unlist(strsplit(as.character(x), ' & ', fixed = T, useBytes = T))
  if(length(x_) == 1) return(x_)
  else {
    aux <- x_[1]
      for (i in 2:length(x_))
        if (i == length(x_)){
          aux <- paste(aux, ' \\& \\\\ ', x_[i], sep = '')
        } else {
          aux <- paste(aux, ',\\\\ ', x_[i], sep = '')
        }
  }
  return(paste('\\begin{tabular}[t]{@{}l@{}}', aux,'\\end{tabular}', 
                   sep = ''))
}
aux <- dat %>%
  select(authoryear, journalCode, locationISO, depvar2, method, instdesign, elecsys3, year) %>%
  unique() %>%
  arrange(year, depvar2)
aux2 <- aux %>%
  mutate(depvar2 = 'aux') %>%
  unique()
for(i in 1:dim(aux)[1]) {
  if(aux2$depvar2[aux2$authoryear == aux$authoryear[i]] == 'aux') {
    aux2$depvar2[aux2$authoryear == aux$authoryear[i]] = aux$depvar2[i]
  } else {
    aux2$depvar2[aux2$authoryear == aux$authoryear[i]] = paste(
      aux2$depvar2[aux2$authoryear == aux$authoryear[i]],
      aux$depvar2[i], sep = ', ')
  }
}
aux <- aux2
for (i in 1:dim(aux)[1]) {
  cat(paste(build_nams(aux$authoryear[i]), ' & ', aux$journalCode[i], ' & ',
      aux$locationISO[i], ' & ', aux$depvar2[i], ' & ', 
      aux$method[i], ' & ', aux$instdesign[i], ' & ', 
      aux$elecsys3[i], ' \\\\ [0.5ex]', sep = ''), '\n')
}
```
\bottomrule
\label{tab:papers}
\begin{minipage}{\textwidth}
\renewcommand{\footnoterule}{}
\vspace{-0.5cm}
\footnotetext{\textbf{Journal:} Unpub$=$Unpublished, JPE$=$Journal of Political
Economy, EJPE$=$European Journal of Political Economy, PC$=$Public Choice,
JPubE$=$Journal of Public Economics, JPriE$=$Journal of Private Enterprise,
APSR$=$American Political Science Review, SEJ$=$Southern Economic Journal,
UAR$=$Urban Affairs Review, SCID$=$Studies in Comparative International
Development, SSQ$=$Social Science Quarterly, SPPQ$=$State Politics and Policy
Quarterly, CPS$=$Comparative Political Studies, RivPE$=$Rivista di Politica
Economica, E\&P$=$Economics and Politics, NTJ$=$National Tax Journal.}
\footnotetext{\textbf{Country:} Country codes follow the ISO 3166-1 alpha-3
international standard.} 
\footnotetext{\textbf{Dependent Variable:} ExpPC$=$Per capita expenditure,
logExpPC$=$Natural logarithm of per capita expenditure, PCTGDP$=$Expenditure as
a percentage of GDP.}
\footnotetext{\textbf{Method:} OLS$=$Ordinary least squares, IV$=$Instrumental
variables, Panel$=$Panel data/fixed effects, RDD$=$Regression discontinuity
design.}
\footnotetext{\textbf{Electoral System:} M$=$Majoritarian, NM$=$Non-majoritarian (mixed or proportional
representation).} 
\end{minipage} 
\end{longtable}
\normalsize

Our study sample reflects the development of the literature. Although the "law
of $1/n$" was first formulated in 1981, the empirical assessment of the theory
only started a few years later, as dates of publishing range from `r min(dat$year)`
to `r max(dat$year)`. Most studies focus on the United States (`r as.numeric(table(unique(dat[,c('id','locationISO')])$locationISO)[which(names(table(unique(dat[,c('id','locationISO')])$locationISO))=='USA')])`), but our sample also contains
papers on Australia (`r as.numeric(table(unique(dat[,c('id','locationISO')])$locationISO)[which(names(table(unique(dat[,c('id','locationISO')])$locationISO))=='AUS')])`), Brazil (`r as.numeric(table(unique(dat[,c('id','locationISO')])$locationISO)[which(names(table(unique(dat[,c('id','locationISO')])$locationISO))=='BRA')])`), Germany (`r as.numeric(table(unique(dat[,c('id','locationISO')])$locationISO)[which(names(table(unique(dat[,c('id','locationISO')])$locationISO))=='DEU')])`), Indonesia (`r as.numeric(table(unique(dat[,c('id','locationISO')])$locationISO)[which(names(table(unique(dat[,c('id','locationISO')])$locationISO))=='IDN')])`), Italy (`r as.numeric(table(unique(dat[,c('id','locationISO')])$locationISO)[which(names(table(unique(dat[,c('id','locationISO')])$locationISO))=='ITA')])`), and
Switzerland (`r as.numeric(table(unique(dat[,c('id','locationISO')])$locationISO)[which(names(table(unique(dat[,c('id','locationISO')])$locationISO))=='CHE')])`). Eight articles use cross-national data and analyse from 2 to 110
countries. Early studies used OLS and panel data methods to estimate the
results, while studies from 2012 onward have also applied causal inference
designs such as instrumental variables and regression discontinuity models to
test the relationship between house size and public spending.

Regarding the dependent variables included in the sample, `r as.numeric(table(unique(dat[,c('id','depvar2')])$depvar2)[which(names(table(unique(dat[,c('id','depvar2')])$depvar2))=='ExpPC')])` studies employ
public expenditure per capita, `r as.numeric(table(unique(dat[,c('id','depvar2')])$depvar2)[which(names(table(unique(dat[,c('id','depvar2')])$depvar2))=='logExpPC')])` papers use its natural logarithm, and `r as.numeric(table(unique(dat[,c('id','depvar2')])$depvar2)[which(names(table(unique(dat[,c('id','depvar2')])$depvar2))=='PCTGDP')])` of them
analyse the impact of legislature size on public expenditures as a percentage of
GDP. This indicates that the area has refined the original definition of the "law of $1/n$"
and tested the impact of larger legislatures on different measures of government
spending. Our independent variables are lower chamber size 
(`r as.numeric(table(dat$indepvar2)[which(names(table(dat$indepvar2))=='N')])`), the natural
logarithm of lower chamber size (`r as.numeric(table(dat$indepvar2)[which(names(table(dat$indepvar2))=='logN')])`), and upper chamber size (`r as.numeric(table(dat$indepvar2)[which(names(table(dat$indepvar2))=='K')])`). 
These six variables formed a $3 \times 3$ table, yet not all combinations were
available in the data. We found no studies that correlate public expenditure
per capita with either upper chamber size or the natural logarithm of lower
house size. Thus, our meta-analysis contains seven of the nine possible
variable combinations.

We also coded five moderators that may help us understand the heterogeneity in
the reported results. We included them in our meta-regressions alongside an
indicator for the type of independent variable used in the original study. The
additional moderators are: 1) publication year; 2) paper publication in an
academic journal; 3) estimation method; 4) institutional design; 5) electoral
system. Since the literature on the "law of $1/n$" is notably diverse, we
added only moderators that either refer to important theoretical questions,
such as the effect of the electoral system on public spending, or to essential
characteristics of the publications themselves. Although more moderators exist
in the literature (e.g., data aggregation level), they do not appear as often
as necessary for their inclusion in the meta-regressions. Table
\ref{tab:descriptive} shows the descriptive statistics of the moderator
variables. 

\vspace{.5cm}

\footnotesize
```{r descriptive, warning=F, message=F, echo = FALSE, cache=TRUE, results='asis'}
fulldat$usemeta2 <- factor(fulldat$usemeta)
levels(fulldat$usemeta2) <- c("Other coefficients", "Main sample")
aux <- select(fulldat, usemeta2, indepvar2, elecsys2, method,
              year, published, instdesign) %>%
  rename(`Independent Variables` = indepvar2,
         `Year`                  = year,
         `Published work`        = published,
         `Estimation method`     = method,
         `Institutional Design`  = instdesign,
         `Electoral system`      = elecsys2)
aux$`Independent Variables` <- recode(aux$`Independent Variables`,
                                      `N` = "Lower Chamber Size",
                                      `K` = "Upper Chamber Size",
                                      `logN` = "Log of Lower Chamber Size")
aux$`Electoral system` <- recode(aux$`Electoral system`,
                                 `Non-Maj` = "Non-Majoritarian",
                                 `Maj` = "Majoritarian")
aux <- select(aux, usemeta2, `Independent Variables`, Year, `Published work`, `Estimation method`, `Institutional Design`, `Electoral system`)

export2md(descrTable(~.-usemeta2, aux, y = aux$usemeta2,
                        show.p.overall = F, show.all = T),
          caption = "Descriptive statistics of moderators",
          format  = "latex")
```
\normalsize

A key methodological issue we had to address concerns the potential violation
of an important assumption in a meta-analysis, that of effect size independence
[@cheung2014modeling; @cheung2019guide; @veroniki2016methods]. In our study
sample, authors frequently use similar datasets in their models,
and almost all papers fit more than one regression with similar variables, what
suggests that the assumption above does not hold. We use two procedures to tackle this
problem. First, we created two sets of study coefficients to reduce the impact
of multicollinearity in our estimations. The first group includes only the most
rigorous models from each paper, that is, those estimated with the largest $n$,
most control variables, and fixed effects if the authors added them. If the
article employed a regression discontinuity design, we chose the coefficient
from the optimal bandwidth or from the intermediate one. This sample
encompasses `r dim(dat)[1]` estimates, as `r as.numeric(sum(table(table(dat$id))[-1]))`
articles analysed two dependent or independent variables of
interest\footnote{The papers that used more than one dependent or independent
variable of interest are \citet{baqir1999districts, bjedov2014impact,
bradbury2001legislative, chen2007law, crowley2019law, erler2007termlimits,
gilligan2001fiscal, lee2016supermajority, lee2018court,
maldonado2013legislatures, primo2006stop, ricciuti2003trading,
ricciuti2004legislatures}.}. Our second sample, in contrast, contains all the
`r dim(fulldat)[1]` effect sizes reported in the `r length(unique(dat$id))`
papers. Here we focus on the results for our restricted sample as we consider
them more robust, but the findings are very similar when we use the extended
set.

Our second procedure consists of employing multilevel random effect models
[@cheung2014modeling; @matthes2019meta] in all of our estimations. We add two
extra levels to the regular meta-analysis, one including a unique publication
ID for each paper, and another indicating the data source used in the original
study. By adding these two levels, we account for within- and between-study
variation, thus removing these sources of effect size dependency and improving
the accuracy of the results. More information about the multilevel models can
be found in Section H of the Supplementary Material. 

We use Hedges' $g$ to calculate effect sizes in our meta-analysis
[@hedges1981distribution]. While there are other methods to standardise
coefficients in meta-analytic studies, Hedges' $g$ corrects for upward bias in
small sample sizes and is considered more robust than measures such as Cohen's
$d$ [@lakens2013calculating]. We estimate the Standardised Mean Difference
(SMD), which represents the effect size in each study relative to the
variability observed in that study, by extracting the coefficients and the
standard errors from all articles included in our sample and converting them to
Hedges' $g$. In cases where authors did not report the standard errors for
their estimates, we computed them using the t-statistic presented in the
original tables. 

# Results

The "law of $1/n$" states that more legislators increase government
expenditure. In this paper, we employ three methods to test the empirical
validity of that relationship. First, we run binomial z-tests to assess the
frequency of positive and negative coefficients in our sample. Then, we fit 9
multilevel meta-analyses using the `meta` [@balduzzi2019perform] and the
`dmetar` [@dmetar2019] packages for the `R` statistical language [@rstats2019].
Lastly, we run two sets of meta-regressions to measure the effects of a group
of moderators on the effect sizes of our study sample. To recapitulate, our
independent variables of interest are lower chamber size, the natural logarithm
of lower chamber size, and upper chamber size. The dependent variables are
public expenditure per capita, the natural logarithm of public expenditure per
capita, and government expenditure as a percentage of GDP. Since the outcomes
have different scales, we treat them separately in our models.

```{r, cache=TRUE, echo = FALSE}
aux <- filter(dat, indepvar2 == "N")
binN <- binom.test(table(aux$scoef)[2], sum(table(aux$scoef)), p = 0.5)
aux <- filter(dat, indepvar2=='K')
binK <- binom.test(table(aux$scoef)[2], sum(table(aux$scoef)), p=0.5)
aux <- filter(dat, indepvar2 == "logN")
binlogN <- binom.test(table(aux$scoef)[2], sum(table(aux$scoef)), p = 0.5)
```

## Binomial Z-Tests
\label{sub:binomial}

The binomial z-test evaluates whether the majority of the coefficients of our
independent variables are positive or negative[^binomial]. If increasing the
number of legislators leads to higher public expending, we should expect most
coefficients to be positive. Conversely, if the "reverse law of $1/n" is true,
our results should indicate that $p < 0.5$, that is, the proportion of positive
coefficients is lower than 0.5. The null hypothesis here states that the sign
of the coefficient is equally likely to be positive or negative.  

[^binomial]: Since coefficients are either positive or negative, each of them
can be considered a Bernoulli trial. Thus, the aggregate results for all papers
follow a Binomial distribution where parameters $n$ equals the number of papers
and $p$ is the chance of a positive coefficient. The "law of $1/n$" can be
reformulated as the chance of $p > 0.5$, which facilitates the testing of the
theory.

We start with lower house size. Our results indicate that there is no
correlation between the number of legislators in the lower house and public
expenditure (successes = `r as.numeric(binN$statistic)`, trials = `r as.numeric(binN$parameter)`, p~success~ = `r round(as.numeric(binN$estimate), 3)`, 95\% CI = [`r round(as.numeric(binN$conf.int[1]), 3)`; `r round(as.numeric(binN$conf.int[2]), 3)`], $p$-value = `r round(as.numeric(binN$p.value), 3)`). Note that the "law of $1/n$" suggests that there is a positive
association between both. The binomial test for the natural logarithm of lower
chamber size also shows a
non-statistically significant result (successes = `r as.numeric(binlogN$statistic)`, trials = `r as.numeric(binlogN$parameter)`, p~success~ = `r round(as.numeric(binlogN$estimate), 3)`, 95\% CI = [`r round(as.numeric(binlogN$conf.int[1]), 3)`; `r round(as.numeric(binlogN$conf.int[2]), 3)`],
$p$-value = `r round(as.numeric(binlogN$p.value), 3)`). In contrast, we find a
positive result for the number of legislators in the upper house, which is
in line with the mainstream literature (successes = `r as.numeric(binK$statistic)`, trials = `r as.numeric(binK$parameter)`, p~success~ = `r round(as.numeric(binK$estimate), 3)`, 95\% CI = [`r round(as.numeric(binK$conf.int[1]), 3)`; `r round(as.numeric(binK$conf.int[2]), 3)`],
$p$-value = `r round(as.numeric(binK$p.value), 3)`).

## Meta-Analysis
\label{sub:Meta-Analysis}

```{r, echo = FALSE, message = FALSE, warning = FALSE, cache=TRUE}
mod <- list()
# Pooling effects analysis -- ExpPC x N
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'ExpPC')

mod[[1]] <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")

# Pooling effects analysis -- ExpPC x K
aux <- dat %>%
  filter(indepvar2 == 'K',
         depvar2 == 'ExpPC')

mod[[2]] <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
# Pooling effects analysis -- logExpPC x N
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'logExpPC')

mod[[3]] <- metagen(
  coef, SE, data=aux,
  studlab=paste(authoryear),
  comb.fixed = FALSE,
  comb.random = TRUE,
  method.tau = "REML",
  hakn = TRUE,
  prediction = TRUE,
  sm="SMD"
  )

# Pooling effects analysis -- logExpPC x logN
aux <- dat %>%
  filter(indepvar2 == 'logN',
         depvar2 == 'logExpPC')

mod[[4]] <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")

# Pooling effects analysis -- PCTGDP x N
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'PCTGDP')

mod[[5]] <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")

# Pooling effects analysis -- PCTGDP x logN
aux <- dat %>%
  filter(indepvar2 == 'logN',
         depvar2 == 'PCTGDP')

mod[[6]] <- metagen(
  coef, SE, data=aux,
  studlab=paste(authoryear),
  comb.fixed = FALSE,
  comb.random = TRUE,
  method.tau = "REML",
  hakn = TRUE,
  prediction=TRUE,
  sm="SMD"
  )

# Pooling effects analysis -- PCTGDP x K
aux <- dat %>%
  filter(indepvar2 == 'K',
         depvar2 == 'PCTGDP')

mod[[7]] <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")

# Full model - Pooling effects analysis -- PCTGDP x N
aux <- fulldat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'PCTGDP')

mod[[8]] <- metagen(coef, SE, data = aux,
          studlab = paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm = "SMD")


# Full data - Pooling effects analysis -- ExpPC x K
aux <- fulldat %>%
  filter(indepvar2 == 'K',
         depvar2 == 'ExpPC')

mod[[9]] <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
```

We then proceed to the meta-analysis. We matched the house size variables with
our measures of government spending and created a theoretical $3 \times 3$
matrix. Out of the 9 possible variable combinations, we found only 7 in the
article pool. Our sample does not contain any papers that analyse the
relationships between the log lower chamber size and public expenditure per
capita, or between upper chamber size and the logarithm of public expenditure
per capita. We calculated the effect sizes by drawing the coefficients and
standard errors from the articles and computing Hedges' $g$, which is a widely
used measure of standardised difference between means. When standard errors
were not directly available in the texts, we used t-statistics to retrieve
them. 

Figure \ref{fig:plots} shows the forest plots for our restricted sample, which
includes the `r dim(dat)[1]` main coefficients of the `r length(unique(dat$id))`
selected papers.\footnote{Please refer to Sections H and I in the Supplementary
Material for full results regarding both samples.} On the left side of the
plots are the names of the study authors and paper publication year. For
unpublished studies, we included the first year the paper was available online.
The bars in the middle show the reported effect sizes and the vertical lines
indicate their average, weighted by standard errors. The length of the lines
represent the precision of the estimates. The red line at the bottom of the
figures displays the overall effects plus their respective confidence
intervals.

\begin{landscape}
\begin{figure}[!ht]
\centering
\caption{Forest plots of the relationship between legislature size and government spending (reduced sample)}
\vspace{0.3cm}
\includegraphics[width=25cm,height=17cm]{../graphs/graph1.pdf}
\label{fig:plots}
\end{figure}
\end{landscape}

The uppermost row shows the results for lower chamber size in our restricted
sample. In the first model, which correlates lower house and expenditure per
capita, we find a standardised mean difference (SMD) of 0.022 and a standard
error of 0.131 (studies = `r mod[[1]]$k`, 95\% CI = [-0.256; 0.299], $p$-value
= 0.87), so we cannot rule that the effect is different from zero. Indeed, the
effect of lower chamber size on the other two dependent variables is also null
in statistical terms. When we compare lower chamber size with log expenditure
per capita, the overall effect size is -0.031 and the standard error is 0.049
(studies = `r mod[[3]]$k`, 95\% CI = [-0.188; 0.127], $p$-value = 0.58), and
the impact of larger lower houses on government spending as a percentage of GDP
is also negligible (studies = `r mod[[5]]$k`, SMD = - 0.006, 95\% CI =
[-0.0334; 0.021], $p$-value = 0.563). The results are virtually identical when
we estimate the meta-analyses using our extended sample, and the all three
coefficients are again statistically indistinguishable from zero. 

Next, we present the meta-analyses using the logarithm of lower house size as
an independent variable. The relationship between this variable and the log of
per capita expenditure is positive, but the coefficient is not significant
(studies = `r mod[[4]]$k`, SMD = 0.078, SE = 0.109, 95\% CI = [-0.225; 0.381],
$p$-value = 0.515. The effect of log lower house size on expenditure as a
percentage of the GDP is very similar, although the SMD is negative (studies =
`r mod[[6]]$k`, SMD = `r round(mod[[6]]$TE.random,3)`, SE = 
`r round(mod[[6]]$seTE.random,3)`, 95\% CI = [`r round(mod[[6]]$lower.random,3)`;
`r round(mod[[6]]$upper.random,3)`], $p$-value = 
`r round(mod[[6]]$pval.random,3)`). Results in the full sample are also null, and
the coefficients for each dependent variable have the same sign as the
restricted sample -- positive and negative, respectively.

The third set of models uses upper house size as the main independent variable.
We find a positive correlation between this variable and expenditure per capita
(studies = `r mod[[2]]$k`, SMD = 3.658, SE = 4.299, 95\% CI = [-6.255; 13.572],
$p$-value = 0.419), and a negative relationship with government spending as a
percentage of GDP (studies = `r mod[[7]]$k`, SMD = 
`r round(mod[[7]]$TE.random,3)`, SE = `r round(mod[[7]]$seTE.random,3)`, 95\% CI =
[`r round(mod[[7]]$lower.random,3)`; `r round(mod[[7]]$upper.random,3)`],
$p$-value = `r round(mod[[7]]$pval.random,3)`), yet neither coefficient is
statistically significant. Results are the same in our extended sample.

Taken together, these results yield conservative interpretations. Besides all
average effect sizes not reaching conventional levels of statistical
significance, the studies are also notably heterogeneous. The $I^2$ statistic
quantifies the degree of heterogeneity among studies. @higgins2019cochrane
consider any $I^2$ value above 75\% to indicate high heterogeneity, and the
lowest $I^2$ we find in the restricted sample is `r round(mod[[2]]$I2*100,
2)`\% (for the subset of upper chamber size and per capita expenditure).
Additionally, all prediction intervals encompass zero. Therefore, we cannot
reject the null hypothesis that the effect size is zero in any variable
combination.

In a nutshell, we do not find evidence in favour of the "law of $1/n$".
One reason for this may be the identification strategy authors use in their
models. On the one hand, OLS and panel data models require too many controls to
make units comparable, and they are vulnerable to omitted variable bias or
post-treatment bias [@cinelli2020making; @pearl2015conditioning]. On the other
hand, estimation methods such as instrumental variables (IV) and regression
discontinuity designs (RDD) have become popular because of their high internal
validity [@angrist2008mostly]. Figure \ref{fig:plots2} shows the disaggregated
effects for two sets of models that employ causal estimation techniques. They
measure the impact of lower house size on expenditure per capita (left) and on
the natural logarithm of expenditure per capita (right).

\vspace{.5cm}

\begin{figure}[htb]
\begin{center}
\caption{Forest plots of the relationship between legislature size and government spending with regression method heterogeneity (restricted sample)}
\vspace{.3cm}
\includegraphics[width=1\linewidth, height=7.5cm]{../graphs/graph2.pdf}
\label{fig:plots2}
\end{center}
\end{figure}

Papers that employ instrumental variables and panel/fixed-effects models show
somewhat symmetrical distributions. Out of the five papers listed under IV, two
are positive, two are negative, and one is null. In the plot for panel data,
although more studies accumulate negative coefficients, the positive shifts are
more pronounced, so the overall effect is also null. In contrast, all papers
that use regression discontinuity designs show negative and statistically
significant results. Since only three papers in our sample use RDDs, we are
cautious about predicting an overall negative relationship, but they do
indicate that better identification strategies yield a zero-to-negative impact
of legislature size on expenditure, in support of the "reverse law of $1/n$".

## Meta-Regressions
\label{sub:regressions}

In this section, we run a series of meta-regressions with six moderators to
account for the heterogeneity across the selected papers. The first variable
indicates whether the study uses lower chamber size, log lower chamber size, or
upper chamber size as a main explanatory variable. We include separate effect
sizes for upper and lower chamber sizes when papers analysed both. The second
variable shows the study publication year, which we included to capture
temporal variation in the study coefficients. We also add a dummy variable to
assess whether published articles report effect sizes that are higher or lower
than those from working papers. The fourth variable measures whether studies
focusing on non-majoritarian electoral systems report coefficients that are
smaller or larger than those from majoritarian countries. The fifth covariate
is a categorical variable indicating the statistical procedure used in the
original models (panel data, instrumental variables, OLS, or regression
discontinuity design). In our last variable, we separate coefficients produced
from samples of unicameral or bicameral systems, and code papers that analyse
multiple polities with different institutional designs as "mixed".

Table {tab:regressions} presents the meta-regression results for our restricted
and extended samples. Each column represents one of the three measures of
public spending we discuss in this paper, and the last one uses all
coefficients. To reduce the risk of false positives in our analyses, we use
permutation tests to calculate significance levels for the meta-regressions
\citep{higgins2004controlling}. To interpret these results, the sign of
coefficients matters the most. These meta-regression coefficients can be viewed
as representing "the effect of the moderator on the $1/n$ effect". This means
positive coefficients predict a strengthening of the $1/n$ effect, and negative
ones predict it will get weaker under that moderator category, when compared to
its reference category. Since we aggregate different types of independent
variables under the same models, the size of the effects does not accurately
translate the scale of variations.

```{r, echo = FALSE, warning = FALSE, message = FALSE, results = 'hide', cache = TRUE}
res <- list()

# Aux fctns
strep <- function (x) {
  if(!is.na(x)) {
    return(ifelse(x<0.01, '***',ifelse(x<0.05,'**', ifelse(x<0.1,'*',''))))
  } else {
    return('')
  }
}

extract_coefs <- function(mod, modnam) {
  dfr <- data.frame(
     nams2 = row.names(mod[["beta"]]),
     est = mod[["beta"]],
     se = mod[["se"]],
     pval = mod[["pval"]],
     model = modnam
  )
  aux <- data.frame(nams = c("Intercept",
             "Indepvar: logN",
             "Indepvar: N",
             "Year",
             "Published",
             "Elecsys: Non-Majoritarian",
             "Method: Panel",
             "Method: IV",
             "Method: RDD",
             "Legislature: Mixed",
             "Legislature: Unicameral"), 
             nams2 = c("intrcpt", 
                       "indepvar2logN", 
                       "indepvar2N", 
                       "year", 
                       "publishedYes", 
                       "elecsys2Non-Maj", 
                       "methodPANEL", 
                       "methodIV", 
                       "methodRDD",
                       "instdesignMixed",
                       "instdesignUnicameral"))
  dfr <- left_join(aux, dfr) %>%
    mutate_if(is.numeric, list(~round(., digits = 4)))
  dfr$nams2 <- NULL
  return(dfr)
}

gcf <- function(mod, pos) {
  x <- mod$est[pos]
  y <- mod$pval[pos]
  if(!is.na(x)) {
    return(paste0(format(round(x, digits = 3), nsmall = 3), strep(y)))
  } else {
    return('')
  }
}
gcf2 <- function(mod, pos) {
  x <- mod$se[pos]
  if(!is.na(x)) {
    return(paste0('(', format(round(x, digits = 3), nsmall = 3), ')'))
  } else {
    return('')
  }
}

# Expenditure per capita - Restricted
mod <- rma.mv(yi = coef,
              V = VAR,
              data = dat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              sparse = TRUE,
              tdist = TRUE,
              subset = dat$depvar2=='ExpPC',
              slab = dat$authoryear)

res[[1]] <- extract_coefs(mod, "ExpPC")

# Expenditure per capita - Extended
mod <- rma.mv(yi = coef,
              V = VAR,
              data = fulldat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              tdist = TRUE,
              sparse = TRUE,
              subset = fulldat$depvar2=='ExpPC',
              slab = fulldat$authoryear)

res[[2]] <- extract_coefs(mod, "ExpPC - All coefs")

# Log of Expenditure per capita - Restricted
mod <- rma.mv(yi = coef,
              V = VAR,
              data = dat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              tdist = TRUE,
              sparse = TRUE,
              subset = dat$depvar2=='logExpPC',
              slab = dat$authoryear)

res[[3]] <- extract_coefs(mod, "logExpPC")

# Log of Expenditure per capita - Extended
mod <- rma.mv(yi = coef,
              V = VAR,
              data = fulldat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              tdist = TRUE,
              sparse = TRUE,
              subset = fulldat$depvar2=='logExpPC',
              slab = fulldat$authoryear)

res[[4]] <- extract_coefs(mod, "logExpPC - All coefs")

## Expenditure as percentage GDP -- Restricted
mod <- rma.mv(yi = coef,
              V = VAR,
              data = dat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              tdist = TRUE,
              sparse = TRUE,
              subset = dat$depvar2=='PCTGDP',
              slab = dat$authoryear)

res[[5]] <- extract_coefs(mod, "PCTGDP")

## Expenditure as percentage GDP -- Extended
mod <- rma.mv(yi = coef,
              V = VAR,
              data = fulldat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              tdist = TRUE,
              sparse = TRUE,
            subset = fulldat$depvar2=='PCTGDP',
            slab = fulldat$authoryear)

res[[6]] <- extract_coefs(mod, "PCTGDP - All coefs")

mod <- rma.mv(yi = coef,
              V = VAR,
              data = dat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~depvar2+indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              tdist = TRUE,
              sparse = TRUE,
              slab = dat$authoryear)

res[[7]] <- extract_coefs(mod, "Full Model")

mod <- rma.mv(yi = coef,
              V = VAR,
              data = fulldat,
              method = "REML",
              random = ~ 1 | id_level1/id_level2, 
              mods = ~depvar2+indepvar2+year+published+elecsys2+method+instdesign,
              test = "knha",
              tdist = TRUE,
              sparse = TRUE,
              slab = fulldat$authoryear)

res[[8]] <- extract_coefs(mod, "Full Model - All coefs")
```

\vspace{0.5cm}

```{=latex}
\begin{table}[htpb]
\caption{Meta Regression Results\label{tabregressions}}
\scriptsize
\centering
\begin{tabular}{lcccccccc}
\toprule
\midrule
\multicolumn{1}{c}{ } & \multicolumn{2}{c}{Expenditure Per Capita} & \multicolumn{2}{c}{Log Expenditure Per Capita} & \multicolumn{2}{c}{Gov. Spending \% GDP} & \multicolumn{2}{c}{All Coefficients} \\
\cmidrule(l{3pt}r{3pt}){2-3} \cmidrule(l{3pt}r{3pt}){4-5} \cmidrule(l{3pt}r{3pt}){6-7} \cmidrule(l{3pt}r{3pt}){8-9}
& Restricted & Extended & Restricted & Extended & Restricted & Extended & Restricted & Extended \\
\midrule
Log of Lower Chamber Size & 
`r gcf(res[[1]], 2)` & `r gcf(res[[2]], 2)` & 
`r gcf(res[[3]], 2)` & `r gcf(res[[4]], 2)` & 
`r gcf(res[[5]], 2)` & `r gcf(res[[6]], 2)` &
`r gcf(res[[7]], 2)` & `r gcf(res[[8]], 2)` \\
 & `r gcf2(res[[1]], 2)` & `r gcf2(res[[2]], 2)` & 
`r gcf2(res[[3]], 2)` & `r gcf2(res[[4]], 2)` & 
`r gcf2(res[[5]], 2)` & `r gcf2(res[[6]], 2)` & 
`r gcf2(res[[7]], 2)` & `r gcf2(res[[8]], 2)` \\
%
Lower Chamber Size &
`r gcf(res[[1]], 3)` & `r gcf(res[[2]], 3)` & 
`r gcf(res[[3]], 3)` & `r gcf(res[[4]], 3)` & 
`r gcf(res[[5]], 3)` & `r gcf(res[[6]], 3)` &
`r gcf(res[[7]], 3)` & `r gcf(res[[8]], 3)` \\
 & `r gcf2(res[[1]], 3)` & `r gcf2(res[[2]], 3)` & 
`r gcf2(res[[3]], 3)` & `r gcf2(res[[4]], 3)` & 
`r gcf2(res[[5]], 3)` & `r gcf2(res[[6]], 3)` & 
`r gcf2(res[[7]], 3)` & `r gcf2(res[[8]], 3)` \\
%
Year & 
`r gcf(res[[1]], 4)` & `r gcf(res[[2]], 4)` & 
`r gcf(res[[3]], 4)` & `r gcf(res[[4]], 4)` & 
`r gcf(res[[5]], 4)` & `r gcf(res[[6]], 4)` &
`r gcf(res[[7]], 4)` & `r gcf(res[[8]], 4)` \\
& `r gcf2(res[[1]], 4)` & `r gcf2(res[[2]], 4)` & 
`r gcf2(res[[3]], 4)` & `r gcf2(res[[4]], 4)` & 
`r gcf2(res[[5]], 4)` & `r gcf2(res[[6]], 4)` & 
`r gcf2(res[[7]], 4)` & `r gcf2(res[[8]], 4)` \\
%
Non-Majoritarian & 
`r gcf(res[[1]], 5)` & `r gcf(res[[2]], 5)` & 
`r gcf(res[[3]], 5)` & `r gcf(res[[4]], 5)` & 
`r gcf(res[[5]], 5)` & `r gcf(res[[6]], 5)` &
`r gcf(res[[7]], 5)` & `r gcf(res[[8]], 5)` \\
& `r gcf2(res[[1]], 5)` & `r gcf2(res[[2]], 5)` & 
`r gcf2(res[[3]], 5)` & `r gcf2(res[[4]], 5)` & 
`r gcf2(res[[5]], 5)` & `r gcf2(res[[6]], 5)` & 
`r gcf2(res[[7]], 5)` & `r gcf2(res[[8]], 5)` \\
%
Published: Yes & 
`r gcf(res[[1]], 6)` & `r gcf(res[[2]], 6)` & 
`r gcf(res[[3]], 6)` & `r gcf(res[[4]], 6)` & 
`r gcf(res[[5]], 6)` & `r gcf(res[[6]], 6)` &
`r gcf(res[[7]], 6)` & `r gcf(res[[8]], 6)` \\
& `r gcf2(res[[1]], 6)` & `r gcf2(res[[2]], 6)` & 
`r gcf2(res[[3]], 6)` & `r gcf2(res[[4]], 6)` & 
`r gcf2(res[[5]], 6)` & `r gcf2(res[[6]], 6)` & 
`r gcf2(res[[7]], 6)` & `r gcf2(res[[8]], 6)` \\
%
Method: Panel & 
`r gcf(res[[1]], 7)` & `r gcf(res[[2]], 7)` & 
`r gcf(res[[3]], 7)` & `r gcf(res[[4]], 7)` & 
`r gcf(res[[5]], 7)` & `r gcf(res[[6]], 7)` &
`r gcf(res[[7]], 7)` & `r gcf(res[[8]], 7)` \\
& `r gcf2(res[[1]], 7)` & `r gcf2(res[[2]], 7)` & 
`r gcf2(res[[3]], 7)` & `r gcf2(res[[4]], 7)` & 
`r gcf2(res[[5]], 7)` & `r gcf2(res[[6]], 7)` & 
`r gcf2(res[[7]], 7)` & `r gcf2(res[[8]], 7)` \\
%
Method: IV & 
`r gcf(res[[1]], 8)` & `r gcf(res[[2]], 8)` & 
`r gcf(res[[3]], 8)` & `r gcf(res[[4]], 8)` & 
`r gcf(res[[5]], 8)` & `r gcf(res[[6]], 8)` &
`r gcf(res[[7]], 8)` & `r gcf(res[[8]], 8)` \\
& `r gcf2(res[[1]], 8)` & `r gcf2(res[[2]], 8)` & 
`r gcf2(res[[3]], 8)` & `r gcf2(res[[4]], 8)` & 
`r gcf2(res[[5]], 8)` & `r gcf2(res[[6]], 8)` & 
`r gcf2(res[[7]], 8)` & `r gcf2(res[[8]], 8)` \\
%
Method: RDD &
`r gcf(res[[1]], 9)` & `r gcf(res[[2]], 9)` & 
`r gcf(res[[3]], 9)` & `r gcf(res[[4]], 9)` & 
`r gcf(res[[5]], 9)` & `r gcf(res[[6]], 9)` &
`r gcf(res[[7]], 9)` & `r gcf(res[[8]], 9)` \\
& `r gcf2(res[[1]], 9)` & `r gcf2(res[[2]], 9)` & 
`r gcf2(res[[3]], 9)` & `r gcf2(res[[4]], 9)` & 
`r gcf2(res[[5]], 9)` & `r gcf2(res[[6]], 9)` & 
`r gcf2(res[[7]], 9)` & `r gcf2(res[[8]], 9)` \\
% 
Inst. Design: Mixed & 
`r gcf(res[[1]], 10)` & `r gcf(res[[2]], 10)` & 
`r gcf(res[[3]], 10)` & `r gcf(res[[4]], 10)` & 
`r gcf(res[[5]], 10)` & `r gcf(res[[6]], 10)` &
`r gcf(res[[7]], 10)` & `r gcf(res[[8]], 10)` \\
& `r gcf2(res[[1]], 10)` & `r gcf2(res[[2]], 10)` & 
`r gcf2(res[[3]], 10)` & `r gcf2(res[[4]], 10)` & 
`r gcf2(res[[5]], 10)` & `r gcf2(res[[6]], 10)` & 
`r gcf2(res[[7]], 10)` & `r gcf2(res[[8]], 10)` \\
% 
Inst. Design: Unicameral & 
`r gcf(res[[1]], 11)` & `r gcf(res[[2]], 11)` & 
`r gcf(res[[3]], 11)` & `r gcf(res[[4]], 11)` & 
`r gcf(res[[5]], 11)` & `r gcf(res[[6]], 11)` &
`r gcf(res[[7]], 11)` & `r gcf(res[[8]], 11)` \\
& `r gcf2(res[[1]], 11)` & `r gcf2(res[[2]], 11)` & 
`r gcf2(res[[3]], 11)` & `r gcf2(res[[4]], 11)` & 
`r gcf2(res[[5]], 11)` & `r gcf2(res[[6]], 11)` & 
`r gcf2(res[[7]], 11)` & `r gcf2(res[[8]], 11)` \\
% 
Intercept & 
`r gcf(res[[1]], 1)` & `r gcf(res[[2]], 1)` & 
`r gcf(res[[3]], 1)` & `r gcf(res[[4]], 1)` & 
`r gcf(res[[5]], 1)` & `r gcf(res[[6]], 1)` &
`r gcf(res[[7]], 1)` & `r gcf(res[[8]], 1)` \\
& `r gcf2(res[[1]], 1)` & `r gcf2(res[[2]], 1)` & 
`r gcf2(res[[3]], 1)` & `r gcf2(res[[4]], 1)` & 
`r gcf2(res[[5]], 1)` & `r gcf2(res[[6]], 1)` & 
`r gcf2(res[[7]], 1)` & `r gcf2(res[[8]], 1)` \\
\bottomrule
\end{tabular}
\begin{minipage}{\textwidth}
\renewcommand{\footnoterule}{}
\footnotetext{\textbf{Note:} {The restricted and extended samples include `r length(dat$id)` and `r length(fulldat$id)` study coefficients, respectively. We report the results from the permutation tests. Reference categories: Independent Variable: Upper House Size; Published $= No$; Non-Majoritarian; Method $= OLS$, Inst. Design $= Bicameral$. Significance codes: *** $p < 0.01$; ** $p < 0.05$; * $p < 0.10$. Blank cells mean that there is no sufficient data to estimate the paramater.}}
\end{minipage}
\end{table}
```

\vspace{0.5cm}

The first two models show the results for public expenditure per capita. No
variable reaches conventional levels of statistical significance in the
restricted sample. In the extended sample, we find that models that use lower
chamber size as an independent variable have lower effects when compared to
upper chamber size. This suggests that an additional member in the lower house
has a smaller impact on public spending than a member in the upper house.
Moreover, the results for the extended sample point out that recent studies
find larger effects than older ones.

The third and fourth columns use the natural logarithm of expenditure per
capita as the dependent variable. Among the coefficients in the restricted
sample, those in published studies are significantly smaller than those in
working papers. Another two moderators are negatively associated with the
outcome in our larger study pool. They both refer to estimation methods.
Studies that employ panel/fixed effects or regression discontinuity designs
(RDDs) have lower coefficients for log expenditure per capita if we take OLS as
the reference category. 

Three variables are statistically significant in the third set of
meta-regressions, which include public expenditure as a percentage of GDP as
the dependent variable. Both in our restricted and in our extended samples,
recent studies have smaller coefficients than older papers, which stands in
contrast with our previous models. Moreover, institutional design also affects
outcomes. Papers that use mixed samples of bicameral and unicameral systems
report significantly lower coefficients than those that analyse bicameral
legislatures exclusively. Non-majoritarian electoral systems are also
associated with lower levels of public spending, which may be justified since
the "law of $1/n$" was conceived for majoritarian voting. These latter results,
however, do not replicate in the first set of estimations.

The last two columns report meta-regressions that aggregate all selected
studies. In the restricted sample of coefficients, unicameralism has a
pro-$1/n$ effect. This strongly supports the theory's original formulation, as
most unicameral occurrences are local governments, for which the "law" was
originally conceived. This result holds for the extended sample as well. When
we regress all `r dim(fulldat)[1]` coefficients, the effects of estimation
methods become stronger once again. Panel/fixed-effects models and regression
discontinuity designs both decrease the $1/n$ effect at the .1\% significance
level. Instrumental variable models follow along these lines. Additionally,
non-majoritarian voting constituencies appear once again as settings where the
law of $1/n$ becomes weaker.

The evidence seems to be sensitive to the methodological design. Our results
suggest that the same study samples may produce different outcomes depending on
the response variables scholars decide to analyse. The broadest aggregation
level presented the most insightful results in dialogue with the literature.
The additional legislator in non-majoritarian legislatures does not increase
expenditure as much as she would if the system were majoritarian. We are also
more likely to witness legislative expenditure growing along with the amount of
representatives in unicameral legislatures rather than in bicameral systems.
This indicates that while the law of $1/n$ is not generalisable, its predicted
effects are stronger when the institutional features of a polity come closer to
its original theoretical framework.

# Discussion
\label{sec:discussion}

In this letter, we assess the empirical validity of the "law of $1/n$". Based
on a sample of `r length(unique(dat$id))` publications on the topic, our
meta-analyses show that there is no strong evidence that an increase in the
number of legislators has a significant effect on public expenditures. If such
effect exists, it is likely driven by an increase in $k$, the size of the upper
legislature, as suggested by several studies in the literature
[@baqir2002districting; @bradbury2001legislative; @bradbury2003local;
@chen2007law; @gilligan2001fiscal; @primo2006stop]. Instead, we find
better evidence for the "reverse law of $1/n$", which posits that larger
legislatures lead to lower government spending. This is mainly because studies
using regression discontinuity designs, a method that has robust internal
validity, consistently indicate a negative relationship between lower house size
and the logarithm of expenditure per capita [@hohmann2017effect;
@lewis2019legislature; @petterssonlidbom2012size].

The meta-regressions show that study characteristics have a considerable
influence on reported results. Electoral system affects the relationship
between legislature size and public expenditure, but the results are not
replicable in all estimations. Publication year generates conflicting findings
in our models. Nevertheless, the meta-regressions confirm that RDDs produce
negative effects more frequently than OLS regressions.

Why is there no clear-cut evidence in favour or against the "law of $1/n$"? A
plausible reason may be that there are few incentives for the pure accumulation
of knowledge in the social sciences, at least when compared to the benefits
scholars may accrue when they challenge or add features to existing theories
[@geddes2003paradigms]. This leads to a reduced number of replication studies in
the field, although we have seen some positive changes in this respect, such as
EGAP's _Metaketa Initiative_.\footnote{See
\url{https://egap.org/our-work/the-metaketa-initiative} for further
information.} For instance, in our sample, papers added supermajority rules
[@lee2015supermajority; @lee2016supermajority], redistricting
[@baqir2002districting; @lee2018court], party ideology [@bjedov2014impact],
coalition sizes [@baskaran2013coalition], term limits [@erler2007termlimits],
bicameralism [@ricciuti2004legislature], and the interplay between upper and
lower houses [@chen2007law] to the main theory, but a comprehensive
procedural replication of the findings using different samples is yet to be
written. The addition of new features has the benefit of enriching the original
theory with useful details, although it has the disadvantage of not providing a
conclusive test to the "law of $1/n$".

Our analyses suggest three areas for further research. First, our study
sample did not include articles that evaluate the association between the
log($n$) and public expenditure per capita or between $k$ and log expenditure
per capita. New work on that area might clarify some of the inconsistencies we
find here. Second, despite the inclusion of several moderators in our models,
aggregate results still show considerable heterogeneity. Domestic factors such
as party dynamics or gerrymandering [@lee2015supermajority;
@mukherjee2003politicalparties; @gilligan2006public] may prove useful in this
regard. Finally, we highlight the need for more causal inference studies in the
literature. Whenever possible, authors should leverage natural and
quasi-experiments to assess whether the current results hold when tested with
such research designs. These suggestions may help scholars and policy-makers to
reach an optimal balance between sound fiscal policy and the demands for
increased political representation.

\newpage
\setlength{\parindent}{0cm}
\setlength{\parskip}{5pt}

\nocite{baskaran2013coalition, bradbury2009spatially, drew2017price,
erler2007termlimits, fiorino2007legislature, hohmann2017effect,
kessler2014communication, lewis2019legislature, lledo2003electoral,
mukherjee2003politicalparties, petterssonlidbom2012size, schaltegger2009large,
stein1998institutional, mukherjee2003politicalparties, macdonald2008impact,
matsusaka2005endogeneity, ricciuti2004legislatures}


